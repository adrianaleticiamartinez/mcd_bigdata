# mcd_bigdata
Repositorio donde se concentra el desarrollo realizado para el proyecto final de la materia de Grandes Datos de la Maestría en Ciencia de datos de la Universidad Panamericana

# Análisis de Pull Requests en GitHub

Este proyecto tiene como objetivo realizar un análisis de los pull requests en GitHub utilizando técnicas de ciencia de datos y aprendizaje automático.

## Descripción del Proyecto

El análisis de pull requests en GitHub es una tarea importante para comprender la dinámica de colaboración y desarrollo en proyectos de código abierto. En este proyecto, exploramos datos de pull requests de GitHub utilizando Python, BigQuery y Google Cloud Platform. Realizamos análisis exploratorio de datos, entrenamos modelos de aprendizaje automático para predecir ciertos aspectos de los pull requests y generamos visualizaciones para entender mejor los patrones y tendencias en los datos.

## Contenido del Repositorio

- **notebooks**: Este directorio contiene notebooks de Jupyter utilizados para análisis exploratorio de datos, entrenamiento de modelos y visualizaciones.
- **scripts**: En este directorio se encuentran los scripts Python utilizados para extraer datos de GitHub, preprocesarlos y realizar análisis específicos.
- **data**: Aquí se almacenan los datos utilizados en el proyecto. Puede incluir datos de muestra, datos de entrenamiento y prueba, y otros archivos relacionados con los datos.
- **docs**: Este directorio contiene documentación adicional, como manuales de usuario, informes técnicos y otros documentos relevantes.
- **LICENSE**: Archivo de licencia que especifica los términos de uso del código y los datos en este repositorio.
- **README.md**: Este archivo que estás leyendo ahora, que proporciona una descripción general del proyecto y orientación sobre cómo utilizarlo.

## Ejecución del Proyecto

Para ejecutar el proyecto en tu propio entorno, sigue estos pasos:

1. Clona este repositorio en tu máquina local:
   'git clone https://github.com/usuario/nombre-del-repositorio.git'


2. Instala las dependencias necesarias utilizando `pip`:
´pip install -r requirements.txt´


3. Explora los notebooks de Jupyter en el directorio `notebooks` para realizar análisis exploratorio de datos, entrenar modelos y generar visualizaciones.

4. Utiliza los scripts Python en el directorio `scripts` para ejecutar tareas específicas, como la extracción de datos de GitHub o el preprocesamiento de datos.

## Contribuciones y Problemas

Si deseas contribuir a este proyecto o informar sobre problemas, no dudes en abrir un issue o enviar una pull request en GitHub. ¡Todas las contribuciones son bienvenidas!

## Licencia

Este proyecto se distribuye bajo la Licencia MIT. Consulta el archivo LICENSE para obtener más detalles.





